{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ed75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 17 persons, 590.1ms\n",
      "Speed: 15.1ms preprocess, 590.1ms inference, 11.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 18 persons, 570.7ms\n",
      "Speed: 12.2ms preprocess, 570.7ms inference, 5.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 19 persons, 419.9ms\n",
      "Speed: 15.8ms preprocess, 419.9ms inference, 5.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 16 persons, 410.2ms\n",
      "Speed: 17.6ms preprocess, 410.2ms inference, 6.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 18 persons, 402.3ms\n",
      "Speed: 13.9ms preprocess, 402.3ms inference, 6.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 17 persons, 398.2ms\n",
      "Speed: 13.1ms preprocess, 398.2ms inference, 5.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 18 persons, 399.4ms\n",
      "Speed: 12.0ms preprocess, 399.4ms inference, 6.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 16 persons, 402.7ms\n",
      "Speed: 11.9ms preprocess, 402.7ms inference, 5.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 15 persons, 408.7ms\n",
      "Speed: 12.8ms preprocess, 408.7ms inference, 6.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 15 persons, 421.9ms\n",
      "Speed: 12.1ms preprocess, 421.9ms inference, 9.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 15 persons, 446.8ms\n",
      "Speed: 12.3ms preprocess, 446.8ms inference, 8.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 16 persons, 422.9ms\n",
      "Speed: 20.6ms preprocess, 422.9ms inference, 6.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 16 persons, 635.0ms\n",
      "Speed: 12.4ms preprocess, 635.0ms inference, 5.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 17 persons, 396.3ms\n",
      "Speed: 13.0ms preprocess, 396.3ms inference, 6.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 18 persons, 425.4ms\n",
      "Speed: 12.7ms preprocess, 425.4ms inference, 5.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 18 persons, 396.8ms\n",
      "Speed: 12.8ms preprocess, 396.8ms inference, 6.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 15 persons, 400.0ms\n",
      "Speed: 12.3ms preprocess, 400.0ms inference, 6.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 14 persons, 394.4ms\n",
      "Speed: 12.5ms preprocess, 394.4ms inference, 6.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 14 persons, 471.4ms\n",
      "Speed: 13.0ms preprocess, 471.4ms inference, 5.4ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import numpy as np\n",
    "\n",
    "# YOLO 모델 불러오기 (사람 탐지 전용)\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# CCTV 영상 주소 (로컬 파일 또는 RTSP/HTTP 스트리밍 URL 가능)\n",
    "VIDEO_SOURCE = \"../data/iho_beach.mp4\"\n",
    "\n",
    "# 혼잡도 기준 (사람 수)\n",
    "DENSITY_THRESHOLDS = [5, 15]  # 0~4: 낮음, 5~14: 중간, 15+ : 높음\n",
    "\n",
    "# 혼잡도 레벨 색상 (BGR)\n",
    "COLOR_MAP = {\n",
    "    \"낮음\": (0, 255, 0),    # 초록\n",
    "    \"중간\": (0, 255, 255),  # 노랑\n",
    "    \"높음\": (0, 0, 255)     # 빨강\n",
    "}\n",
    "\n",
    "def get_density_level(count):\n",
    "    if count < DENSITY_THRESHOLDS[0]:\n",
    "        return \"낮음\"\n",
    "    elif count < DENSITY_THRESHOLDS[1]:\n",
    "        return \"중간\"\n",
    "    else:\n",
    "        return \"높음\"\n",
    "\n",
    "# 한글 폰트 경로 설정 (윈도우 예: 맑은 고딕)\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\"  # 환경에 맞게 수정 필요\n",
    "font = ImageFont.truetype(font_path, 30)  # 폰트 크기 30\n",
    "\n",
    "# 비디오 스트림 열기\n",
    "cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # YOLO 객체 탐지 (사람 클래스만 추출)\n",
    "    results = model(frame, classes=[0], imgsz=1280, conf=0.2, iou=0.3)\n",
    "\n",
    "    # 탐지된 박스 개수 = 사람 수\n",
    "    person_count = 0\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            person_count += 1\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "    # 혼잡도 계산\n",
    "    density_level = get_density_level(person_count)\n",
    "    density_color = COLOR_MAP[density_level]\n",
    "\n",
    "    # OpenCV 이미지를 PIL 이미지로 변환 (BGR->RGB)\n",
    "    frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(frame_pil)\n",
    "\n",
    "    # PIL로 한글 텍스트 그리기\n",
    "    draw.text((20, 40), f\"인원 수: {person_count}\", font=font, fill=(255, 255, 255))\n",
    "    draw.text((20, 80), f\"혼잡도: {density_level}\", font=font, fill=density_color[::-1])  # RGB로 바꿔줌\n",
    "\n",
    "    # PIL 이미지를 다시 OpenCV 이미지로 변환 (RGB->BGR)\n",
    "    frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # 결과 출력\n",
    "    cv2.imshow(\"Beach Crowd Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_opencv",
   "language": "python",
   "name": "my_opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
